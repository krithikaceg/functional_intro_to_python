{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_of_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krithikaceg/functional_intro_to_python/blob/master/Classification_of_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "O1uoOtCwRJSu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classification of Digits "
      ]
    },
    {
      "metadata": {
        "id": "OD8uWVa6Q1bE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from yellowbrick.classifier import ConfusionMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CGciLb2sRGkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ingest"
      ]
    },
    {
      "metadata": {
        "id": "MOuXmAiuRFmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The digits dataset\n",
        "digits = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "la2XZVpQeEPO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ]
    },
    {
      "metadata": {
        "id": "Ids4Aichqer7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "843e5820-2cc9-4047-e11c-e62eded2cca5"
      },
      "cell_type": "code",
      "source": [
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
        "    plt.subplot(2, 4, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Training: %i' % label)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAACPCAYAAAC256FcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nELIAABghZAEAMELIAgBg5L9HFYFp0SpPKQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fFeRHRGgPPfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "12ebe1f7-5032-4df6-cbd1-4634a5d005c0"
      },
      "cell_type": "code",
      "source": [
        "digits.images[0]"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
              "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
              "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
              "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
              "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
              "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
              "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
              "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "id": "zI1eK_ZAPG5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "5bceda8e-9309-41e2-efeb-aaf7d857e957"
      },
      "cell_type": "code",
      "source": [
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "number_of_digits_to_predict = 8\n",
        "\n",
        "# We are shuffling data, images, target\n",
        "#X, images, y = shuffle(data, digits.images, digits.target, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.33, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "expected = y_test\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        55\n",
            "           1       0.98      1.00      0.99        55\n",
            "           2       1.00      1.00      1.00        52\n",
            "           3       0.98      0.96      0.97        56\n",
            "           4       1.00      1.00      1.00        64\n",
            "           5       0.99      1.00      0.99        73\n",
            "           6       1.00      1.00      1.00        57\n",
            "           7       0.98      0.98      0.98        62\n",
            "           8       0.98      0.98      0.98        52\n",
            "           9       0.99      0.97      0.98        68\n",
            "\n",
            "   micro avg       0.99      0.99      0.99       594\n",
            "   macro avg       0.99      0.99      0.99       594\n",
            "weighted avg       0.99      0.99      0.99       594\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[55  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 55  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 52  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 54  0  1  0  0  1  0]\n",
            " [ 0  0  0  0 64  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 73  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 57  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 61  0  1]\n",
            " [ 0  1  0  0  0  0  0  0 51  0]\n",
            " [ 0  0  0  1  0  0  0  1  0 66]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PVLyEL4w3Xlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87f032fd-e008-4446-f046-1ea50700914d"
      },
      "cell_type": "code",
      "source": [
        "print(classifier.score(X_test, y_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98989898989899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AVBoWGlb6bE3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "YP7GeW4U61Zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "x_train, x_test, y_train, y_test = train_test_split(digits.images, digits.target, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MP4v1MLj7CzG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline # Only use this if using iPython\n",
        "image_index = 77 # You may select anything up to 60,000\n",
        "print(y_train[image_index]) # The label is 8\n",
        "plt.imshow(x_train[image_index], cmap='Greys')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__astikw9KYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "45f2abed-5392-4d7e-aa3e-129592f499a6"
      },
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(x_train.shape)\n",
        "print(type(x_train))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  0.  1. 12.  7.  0.  0.]\n",
            " [ 0.  0.  0.  9. 16. 16.  1.  0.]\n",
            " [ 0.  1.  7. 15. 16. 14.  0.  0.]\n",
            " [ 0.  4. 16. 16. 16. 16.  0.  0.]\n",
            " [ 0.  0.  0.  3. 16. 16.  0.  0.]\n",
            " [ 0.  0.  0.  2. 16. 16.  3.  0.]\n",
            " [ 0.  0.  0.  6. 16. 16.  0.  0.]\n",
            " [ 0.  0.  0.  3. 15. 13.  0.  0.]]\n",
            "(1203, 8, 8)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJbKVnnN87lj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7bf11bf8-3807-48aa-f925-c1d5387d5cd8"
      },
      "cell_type": "code",
      "source": [
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "x_train = x_train.reshape(x_train.shape[0], 8, 8, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 8, 8, 1)\n",
        "input_shape = (8, 8, 1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (1203, 8, 8, 1)\n",
            "Number of images in x_train 1203\n",
            "Number of images in x_test 594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wzTPoQP2wQRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LvGiweS--ZgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0559cd92-9bf7-46a3-da4d-b0a1f2be5311"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=10)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1203/1203 [==============================] - 1s 523us/step - loss: 2.2857 - acc: 0.3267\n",
            "Epoch 2/10\n",
            "1203/1203 [==============================] - 0s 143us/step - loss: 2.2052 - acc: 0.5353\n",
            "Epoch 3/10\n",
            "1203/1203 [==============================] - 0s 133us/step - loss: 1.9904 - acc: 0.5786\n",
            "Epoch 4/10\n",
            "1203/1203 [==============================] - 0s 125us/step - loss: 1.6135 - acc: 0.6958\n",
            "Epoch 5/10\n",
            "1203/1203 [==============================] - 0s 129us/step - loss: 1.2256 - acc: 0.7731\n",
            "Epoch 6/10\n",
            "1203/1203 [==============================] - 0s 133us/step - loss: 0.9192 - acc: 0.8188\n",
            "Epoch 7/10\n",
            "1203/1203 [==============================] - 0s 131us/step - loss: 0.7163 - acc: 0.8479\n",
            "Epoch 8/10\n",
            "1203/1203 [==============================] - 0s 131us/step - loss: 0.5996 - acc: 0.8645\n",
            "Epoch 9/10\n",
            "1203/1203 [==============================] - 0s 125us/step - loss: 0.5056 - acc: 0.8886\n",
            "Epoch 10/10\n",
            "1203/1203 [==============================] - 0s 134us/step - loss: 0.4558 - acc: 0.8928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71514ecba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "id": "vF1SYRIGEXuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51f62fe1-7dfb-4452-c9e7-a415ec9f49ac"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "594/594 [==============================] - 0s 187us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38634405734161736, 0.9124579120565344]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "id": "oAPldoNHEivI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1062
        },
        "outputId": "f20814ca-cdd4-43e4-e82a-b022760e68f0"
      },
      "cell_type": "code",
      "source": [
        "image_index = 444\n",
        "x_test.reshape(x_test.shape[0], 8, 8)\n",
        "plt.imshow(x_test[image_index],cmap='Greys')\n",
        "pred = model.predict(x_test[image_index])\n",
        "print(pred.argmax())"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-8f83095caada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m444\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2701\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAFOCAYAAAA2HY52AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBUADBFVADBEVAHAEFEFAEP/A0n+cNyGL+HxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}